{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import string\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_1 = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate1.csv\"\n",
    "plate_1_repeat = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate1_repeat.csv\"\n",
    "plate_2_1 = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate2_1.csv\"\n",
    "plate_2_2 = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate2_2.csv\"\n",
    "plate_2_3 = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate2_3.csv\"\n",
    "plate_2_repeat = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate2_repeat.csv\"\n",
    "plate_2_repeat_96 = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\plate2_repeat _96.csv\"\n",
    "list_A = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\listA.csv\"\n",
    "list_A_repeat = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\listA_repeat.csv\"\n",
    "list_B = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\listB.csv\"\n",
    "list_B_repeat_end = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\listB_repeat _end.csv\"\n",
    "list_B_repeat_96 = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\listB_repeat _96.csv\"\n",
    "list_C = \"C:\\\\Users\\\\Bartek\\\\OneDrive\\\\Documents\\\\Programming\\\\Python\\\\Test data\\\\listC.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataError(Exception):\n",
    "    pass\n",
    "    \n",
    "class WellNumberError(Exception):\n",
    "    pass\n",
    "    \n",
    "plate_dimensions = {'96':(8, 12), '384':(16, 24)}\n",
    "    \n",
    "class FA:\n",
    "    \"\"\"\n",
    "    :param csv_file: Raw data file in csv format.\n",
    "    :param type: str\n",
    "    :param read_in_info: Information needed to pre-process the data.\n",
    "    :param type: Varies with the data format. Check the appropriate read in function.\n",
    "    :param g_factor: G-factor.\n",
    "    :param type: float\n",
    "    :param data_format: Format in which the raw data was exported (plate1, plate2, listA, listB or listC).\n",
    "    :param type: str \n",
    "    :param wells: Number of wells on the plate.\n",
    "    :param type: int   \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dict, g_factor):\n",
    "        self.g_factor = g_factor\n",
    "        self.data_dict = data_dict\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def read_in_envision(cls, csv_file, data_type='plate', wells=384):\n",
    "        \n",
    "        #row_letters = list(string.ascii_uppercase)[0:plate_dimensions[str(wells)][0]]   # generate a list of letters for well IDs\n",
    "        #col_numbers = list(np.arange(1, plate_dimensions[str(wells)][1]+1).astype(str))   # generate a list of numbers for well IDs\n",
    "        #well_ids = ['%s%s' % (item[0], item[1]) for item in product(row_letters, col_numbers)]   # generate a list of well IDs for the data table\n",
    "\n",
    "        # ensure the correct number of wells was passed\n",
    "        if str(wells) not in plate_dimensions:\n",
    "            raise WellNumberError('Invalid number of wells on the plate, should be 384 or 96.')\n",
    "        \n",
    "        if data_type == 'plate':\n",
    "            try:\n",
    "                init_data = FA.read_in_plate(csv_file, wells)\n",
    "                return cls(init_data[0], init_data[1])\n",
    "            except (ValueError, IndexError):\n",
    "                raise DataError('incorrect data format or file has no data or incorrect well number')\n",
    "            except UnboundLocalError:\n",
    "                raise DataError('File has no data')\n",
    "        \n",
    "        if data_type == 'list':\n",
    "            try:\n",
    "                init_data = FA.read_in_list(csv_file, wells)\n",
    "                return cls(init_data[0], init_data[1])\n",
    "            except (UnboundLocalError, IndexError):\n",
    "                raise DataError('data format incorrect or file has no data')\n",
    "                \n",
    "                \n",
    "    def read_in_plate(csv_file, wells):\n",
    "\n",
    "        \"\"\" Iterates over the raw data file to find the line numbers at which the metadata table and raw data table begin for \n",
    "        each channel and reapeat. Calculates the length of those tables. Finds the G-factor. Determines the format of data (plate 1 or 2).\n",
    "\n",
    "        :param csv_file: Raw data file in csv format.\n",
    "        :param type: str\n",
    "        :param wells: Number of wells on the plate.\n",
    "        :param type: int\n",
    "        :return: read_in_info is a list of tuples (one tuple for each channel) with parameters needed for pandas to read in the csv file. \"\"\"\n",
    "        \n",
    "        with open(csv_file) as file:\n",
    "            all_data_lines = list(csv.reader(file, delimiter=','))   # read the csv file and cast it into a list containing all lines\n",
    "\n",
    "        blank_indices = list(index for index, item in enumerate(all_data_lines) if item == [])   # list containing indices of all blank rows\n",
    "        blanks = np.array(blank_indices)   # convert the list of blank indices to a numpy array\n",
    "        read_in_info = []   # list to store the tuples with parameters needed for pandas to read in the csv file\n",
    "\n",
    "        for index, item in enumerate(all_data_lines):   # iterate over all lines in the csv file\n",
    "            if item != [] and re.findall(r\"Plate information\", item[0]) == ['Plate information'] and re.search(r'Results for', all_data_lines[index + 9][0]) == None and re.findall(r\"Formula\", all_data_lines[index+1][10]) != ['Formula']:\n",
    "                skiprows = index + 9   # Set the skiprows parameter for raw data table\n",
    "                skiprows_meta = index + 1   # Set the skiprows parameter for metadata table\n",
    "                end_of_data = blanks[blanks > skiprows].min()   # Calculate the end of data table by finding the smallest blank index after the beginning of data table\n",
    "                read_in_info.append((skiprows, end_of_data - skiprows + 1, skiprows_meta))   # add the skiprows, caculated number of data lines and skiprows for metadata parameters to the list as a tuple\n",
    "                data_format = 'plate1'\n",
    "\n",
    "            if item != [] and re.findall(r\"Plate information\", item[0]) == ['Plate information'] and re.search(r'Results for', all_data_lines[index + 9][0]) != None:\n",
    "                skiprows = index + 10\n",
    "                skiprows_meta = index + 1\n",
    "                end_of_data = blanks[blanks > skiprows].min()\n",
    "                read_in_info.append((skiprows, end_of_data - skiprows, skiprows_meta))\n",
    "                data_format = 'plate2'\n",
    "\n",
    "            if item != [] and len(item) > 1 and re.findall(r\"G-factor\", item[0]) == [\"G-factor\"]:\n",
    "                g_factor = float(item[4])   \n",
    "        \n",
    "        return FA.pre_process_plate(csv_file, read_in_info, data_format, wells), g_factor #csv_file, read_in_info, g_factor, data_format, wells\n",
    "\n",
    "    \n",
    "    def pre_process_plate(csv_file, read_in_info, data_format, wells):    \n",
    "\n",
    "        \"\"\" Iterates over the raw data file and creates data frames for the data and metadata for each channel, converts them into\n",
    "        a 384 or 96 by 1 format and adds them into a dictionary.\n",
    "\n",
    "        :param csv file: Raw data file in csv format.\n",
    "        :param type: str\n",
    "        :param read_in_info: A list containg tuples with read in parameters for each channel.\n",
    "        :param type: list\n",
    "        :param data_format: Type of plate (plate1 or plate2).\n",
    "        :param type: str\n",
    "        :param wells: Number of wells on the plate.\n",
    "        :param type: int\n",
    "        :return: A dictionary containg a dictionary for each repeat containg the metadata df and a dictionary with s and p channel dfs. \"\"\" \n",
    "        \n",
    "        row_letters = list(string.ascii_uppercase)[0:plate_dimensions[str(wells)][0]]   # generate a list of letters for well IDs\n",
    "        col_numbers = list(np.arange(1, plate_dimensions[str(wells)][1]+1).astype(str))   # generate a list of numbers for well IDs\n",
    "        well_ids = ['%s%s' % (item[0], item[1]) for item in product(row_letters, col_numbers)]   # generate a list of well IDs for the data table\n",
    "\n",
    "        data_frames = {}   # dictionary to store the data frames\n",
    "        counter = 1   # counter incremented by 0.5 to enable alternating labelling of data frames as p or s\n",
    "\n",
    "        for index, item in enumerate(read_in_info):   # iterate over each tuple in the list\n",
    "\n",
    "            if data_format == 'plate1':   # raw data table does not have row and column names so 'names' parameter passed to omit the last column\n",
    "                raw_data = pd.read_csv(csv_file, sep=',', names=col_numbers, index_col=False, engine='python', skiprows=item[0], nrows=item[1], encoding='utf-8')\n",
    "\n",
    "            if data_format == 'plate2':   # raw data table has row an column names, so 'index_col' is 0 to set the first column as row labels\n",
    "                raw_data = pd.read_csv(csv_file, sep=',', index_col=0, engine='python', skiprows=item[0], nrows=item[1], encoding='utf-8')\n",
    "                raw_data.drop(raw_data.columns[-1], axis=1, inplace=True)   # delete the last column because it is empty\n",
    "\n",
    "            # generate df for metadata (number of rows is always 1) and convert measurement time into datetime object   \n",
    "            metadata = pd.read_csv(csv_file, sep=',', engine='python', skiprows=item[2], nrows=1, encoding='utf-8').astype({'Measurement date': 'datetime64[ns]'})\n",
    "            data_as_array = np.reshape(raw_data.to_numpy(), (int(wells), 1))   # convert data frames to numpy arrays and reshape into 1D array\n",
    "\n",
    "            if counter % 1 == 0: \n",
    "                new_data = pd.DataFrame(data=data_as_array, index=well_ids, columns=['p'])   # generate new 384 (or 96) by 1 data frame with p channel data\n",
    "                data_frames[f'repeat_{int(counter)}'] = {'metadata':metadata, 'data': {'p': new_data, 's':''}}   # add data and metadata dfs to the dictionary\n",
    "\n",
    "            if counter % 1 != 0:\n",
    "                new_data = pd.DataFrame(data=data_as_array, index=well_ids, columns=['s'])   # generate new 384 (or 96) by 1 data frame with s channel data\n",
    "                data_frames[f'repeat_{int(counter-0.5)}']['data']['s'] = new_data\n",
    "\n",
    "            counter = counter + 0.5\n",
    "        \n",
    "        return data_frames\n",
    "\n",
    "\n",
    "    def read_in_list(csv_file, wells):\n",
    "\n",
    "        \"\"\" Iterates over the csv file to find  the line numbers at which the metadata table and raw data table\n",
    "        begin. Creates two pandas data frames: for the raw data and metadata.\n",
    "\n",
    "        :param csv_file: Raw data file in csv format.\n",
    "        :param type: str\n",
    "        :param wells: Number of wells on the plate.\n",
    "        :param type: int\n",
    "        :return: A tuple with raw data and metadata dfs.\"\"\"\n",
    "\n",
    "        with open(csv_file) as file:  \n",
    "            all_data_lines = list(csv.reader(file, delimiter=',')) # read the csv file and cast it into a list containing all lines\n",
    "\n",
    "        # set the skiprows to be initially greater than the total number of lines in the files to enable the evaluation of if statement until the 'skiprows' parameter is found\n",
    "        skiprows = len(all_data_lines) + 1 \n",
    "        # list containing indices of all blank rows\n",
    "        blank_indices = list(index for index, item in enumerate(all_data_lines) if item == [])   # list containing indices of all blank rows\n",
    "        blanks = np.array(blank_indices)   # convert the list of blank indices to a numpy array\n",
    "\n",
    "        # iterate over all lines to find beggining of the data table ('skiprows') and determine the format of data  (list A, B, or C)\n",
    "        for index, item in enumerate(all_data_lines):   \n",
    "            if item != [] and len(item) == 1 and re.findall(r\"Plate information\", item[0]) == [\"Plate information\"]:\n",
    "                skiprows_meta = index + 1\n",
    "                end_of_metadata = blanks[blanks > skiprows_meta].min()   # find the end of metadata by finding the smallest blank index after the beginning of metadata\n",
    "                nrows_meta = end_of_metadata - skiprows_meta - 1   # calucalte the length of metadata table (the number f rows depends on the number of repeats)\n",
    "\n",
    "            if item != [] and len(item) >= 2 and re.findall(r\"PlateNumber\", item[0]) == ['PlateNumber'] and re.findall(r\"PlateRepeat\", item[1]) == ['PlateRepeat']:   # find line number with the beggining of the data\n",
    "                skiprows = index - 1\n",
    "                data_format = 'listA'\n",
    "                end_of_data = blanks[blanks > skiprows].min()\n",
    "\n",
    "            if item != [] and len(item) >= 2 and re.findall(r\"Plate\", item[0]) == ['Plate'] and re.findall(r\"Barcode\", item[1]) == ['Barcode']:   # find line number with the beggining of the data\n",
    "                skiprows = index\n",
    "                data_format = 'listB'\n",
    "                end_of_data = blanks[blanks > skiprows].min()\n",
    "\n",
    "            if item != [] and len(item) >= 2 and re.findall(r\"Plate\", item[0]) == ['Plate']  and re.findall(r\"Well\", item[1]) == ['Well']:\n",
    "                skiprows = index\n",
    "                data_format = 'listC'\n",
    "                end_of_data = blanks[blanks > skiprows].min()\n",
    "\n",
    "            if item != [] and re.findall(r\"G-factor\", item[0]) == [\"G-factor\"]:   # find the g factor\n",
    "                g_factor = float(item[4])\n",
    "\n",
    "        nrows = end_of_data - skiprows - 1   # calculate the length of data table\n",
    "\n",
    "        raw_data = pd.read_csv(csv_file, sep=',', engine='python', skiprows=skiprows, nrows=nrows, encoding='utf-8')\n",
    "        raw_metadata = pd.read_csv(csv_file, sep=',', engine='python', skiprows=skiprows_meta, nrows=nrows_meta, encoding='utf-8')\n",
    "\n",
    "        return FA.pre_process_list(raw_data, raw_metadata, data_format, wells), g_factor\n",
    "\n",
    "\n",
    "    def pre_process_list(raw_data, raw_metadata, data_format, wells):\n",
    "\n",
    "        \"\"\"Extracts the data for each channel and repeat from the raw data table and adds to a dictionary.\n",
    "\n",
    "        :param  read_in_info: A tuple containing data frames for raw data and metadata.string representing type of list (A, B, or C).\n",
    "        :param type: tuple\n",
    "        :param data_format: Type of list (A, B, or C).\n",
    "        :param type: str\n",
    "        :return: A dictionary containg a dictionary for each repeat containg the metadata df and a dictionary with s and p channel dfs.\"\"\"\n",
    "\n",
    "        row_letters = list(string.ascii_uppercase)[0:plate_dimensions[str(wells)][0]]   # generate a list of letters for well IDs\n",
    "        col_numbers = list(np.arange(1, plate_dimensions[str(wells)][1]+1).astype(str))   # generate a list of numbers for well IDs\n",
    "        well_ids = ['%s%s' % (item[0], item[1]) for item in product(row_letters, col_numbers)]   # generate a list of well IDs for the data table\n",
    "\n",
    "        data_frames = {}   # dictionary to store data frames\n",
    "        repeats = list(raw_metadata['Repeat'].to_numpy())   # generate a list with repeats based on the metadata table, e.g. for 3 repeats -> [1,2,3]\n",
    "\n",
    "        # remove the '0' from middle position of well numbers (A01 -> A1), done by reassigning the 'Well' column to a Series containing modified well numbers\n",
    "        raw_data['Well'] = raw_data['Well'].apply(lambda x: x[0] + x[2] if x[1] == '0' else x)\n",
    "\n",
    "        for index, repeat in enumerate(repeats):   # iterate over the number of repeats\n",
    "            if data_format == 'listA':\n",
    "                groupped_data = raw_data.groupby(raw_data.PlateRepeat).get_group(repeat)   # group and extract the data by the plate repeat column, i.e. in each iteration get data only for the current repeat \n",
    "\n",
    "                p_groupped = groupped_data.iloc[::3, :]   # extract data only for the p channel, i.e. each third row starting from the first row\n",
    "                s_groupped = groupped_data.iloc[1::3, :]   # extract data only for the s channel, i.e. each third row starting from the second row\n",
    "\n",
    "                p_raw = p_groupped[['Well', 'Signal']]   # extract only the two relevant columns\n",
    "                s_raw = s_groupped[['Well', 'Signal']]   # for each channel\n",
    "\n",
    "            if data_format in ['listB', 'listC']: \n",
    "                # the column naming is different for the first repeat, i.e. just 'Signal', then it's 'Signal.1', 'Signal.2', etc.\n",
    "                if repeat == 1: \n",
    "                    p_raw = raw_data[['Well', 'Signal']]   \n",
    "                    s_raw = raw_data[['Well', f'Signal.{repeat}']]\n",
    "                else:\n",
    "                    p_raw = raw_data[['Well', f'Signal.{repeat + index - 1}']]   # the column to be extracted is calculated in each iteration\n",
    "                    s_raw = raw_data[['Well', f'Signal.{repeat + index}']]\n",
    "\n",
    "            raw_frame = pd.DataFrame(well_ids, columns=['Wells'])\n",
    "            frame = raw_frame.set_index('Wells')\n",
    "            \n",
    "            # set row indices as the well numbers and rename the 'Signal' column to 'p' or 's'\n",
    "            p_raw.set_index('Well', inplace=True)\n",
    "            p_raw.set_axis(['p'], axis=1, inplace=True)\n",
    "            p_channel = frame.join(p_raw)\n",
    "            s_raw.set_index('Well', inplace=True)\n",
    "            s_raw.set_axis(['s'], axis=1, inplace=True)\n",
    "            s_channel = frame.join(s_raw)\n",
    "    \n",
    "            metadata = raw_metadata.iloc[[repeat-1]].astype({'Measurement date': 'datetime64[ns]'})   # extract the row with metadata relevant for each repeat and covert date and time into a datetime object\n",
    "            data_frames[f'repeat_{repeat}'] = {'metadata': metadata, 'data': {'p': p_channel, 's': s_channel}}   # add data frames to the dictionary\n",
    "\n",
    "        return data_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = FA.read_in_envision(csv_file=list_A_repeat, data_type='list', wells=384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.g_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wells</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>20469296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>29296716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3</th>\n",
       "      <td>18210982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A4</th>\n",
       "      <td>23159988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A5</th>\n",
       "      <td>24960618.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P20</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P21</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P22</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P23</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P24</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                s\n",
       "Wells            \n",
       "A1     20469296.0\n",
       "A2     29296716.0\n",
       "A3     18210982.0\n",
       "A4     23159988.0\n",
       "A5     24960618.0\n",
       "...           ...\n",
       "P20           NaN\n",
       "P21           NaN\n",
       "P22           NaN\n",
       "P23           NaN\n",
       "P24           NaN\n",
       "\n",
       "[384 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.data_dict['repeat_1']['data']['s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data2 = FA.read_in_envision(csv_file=list_B_repeat_96, data_type='list', wells=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data2.g_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plate</th>\n",
       "      <th>Repeat</th>\n",
       "      <th>Barcode</th>\n",
       "      <th>Measured height</th>\n",
       "      <th>Chamber temperature at start</th>\n",
       "      <th>Chamber temperature at end</th>\n",
       "      <th>Humidity at start</th>\n",
       "      <th>Humidity at end</th>\n",
       "      <th>Ambient temperature at start</th>\n",
       "      <th>Ambient temperature at end</th>\n",
       "      <th>Measurement date</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.52</td>\n",
       "      <td>18.78</td>\n",
       "      <td>18.68</td>\n",
       "      <td>61.8</td>\n",
       "      <td>62.3</td>\n",
       "      <td>18.88</td>\n",
       "      <td>18.98</td>\n",
       "      <td>2020-11-17 13:39:13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Plate  Repeat  Barcode  Measured height  Chamber temperature at start  \\\n",
       "0      1       1      NaN            14.52                         18.78   \n",
       "\n",
       "   Chamber temperature at end  Humidity at start  Humidity at end  \\\n",
       "0                       18.68               61.8             62.3   \n",
       "\n",
       "   Ambient temperature at start  Ambient temperature at end  \\\n",
       "0                         18.88                       18.98   \n",
       "\n",
       "     Measurement date  Unnamed: 11  \n",
       "0 2020-11-17 13:39:13          NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data2.data_dict['repeat_1']['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wells</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>352962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>357763.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3</th>\n",
       "      <td>541382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A5</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A6</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A7</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A8</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A9</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A10</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A11</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A12</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B5</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B6</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B7</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B8</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B9</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B10</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B11</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B12</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1</th>\n",
       "      <td>344433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C2</th>\n",
       "      <td>431089.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C3</th>\n",
       "      <td>302132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C5</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C6</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C7</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C8</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C9</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C10</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C11</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C12</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D5</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D6</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D7</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D8</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D9</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D10</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D11</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D12</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              p\n",
       "Wells          \n",
       "A1     352962.0\n",
       "A2     357763.0\n",
       "A3     541382.0\n",
       "A4          NaN\n",
       "A5          NaN\n",
       "A6          NaN\n",
       "A7          NaN\n",
       "A8          NaN\n",
       "A9          NaN\n",
       "A10         NaN\n",
       "A11         NaN\n",
       "A12         NaN\n",
       "B1          NaN\n",
       "B2          NaN\n",
       "B3          NaN\n",
       "B4          NaN\n",
       "B5          NaN\n",
       "B6          NaN\n",
       "B7          NaN\n",
       "B8          NaN\n",
       "B9          NaN\n",
       "B10         NaN\n",
       "B11         NaN\n",
       "B12         NaN\n",
       "C1     344433.0\n",
       "C2     431089.0\n",
       "C3     302132.0\n",
       "C4          NaN\n",
       "C5          NaN\n",
       "C6          NaN\n",
       "C7          NaN\n",
       "C8          NaN\n",
       "C9          NaN\n",
       "C10         NaN\n",
       "C11         NaN\n",
       "C12         NaN\n",
       "D1          NaN\n",
       "D2          NaN\n",
       "D3          NaN\n",
       "D4          NaN\n",
       "D5          NaN\n",
       "D6          NaN\n",
       "D7          NaN\n",
       "D8          NaN\n",
       "D9          NaN\n",
       "D10         NaN\n",
       "D11         NaN\n",
       "D12         NaN\n",
       "E1          NaN\n",
       "E2          NaN"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data2.data_dict['repeat_2']['data']['p'].iloc[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
